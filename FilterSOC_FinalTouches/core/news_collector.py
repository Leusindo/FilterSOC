# core/news_collector.py
import feedparser
import requests
from bs4 import BeautifulSoup
import logging
import time
import pandas as pd
from datetime import datetime
from typing import List, Dict
import os
from .config import Config


class NewsCollector:
    """
    Automatick√Ω zber nov√Ωch titulkov z RSS feedov a webov√Ωch str√°nok
    """

    def __init__(self, classifier=None):
        self.config = Config()
        self.logger = logging.getLogger(__name__)
        self.classifier = classifier

        # Zoznam slovensk√Ωch RSS feedov
        self.rss_feeds = [
            # ‚úÖ TYTO FUNGUJ√ö (podƒæa teba):
            "https://www.aktuality.sk/rss/",
            "https://www.teraz.sk/rss/vsetky-spravy.rss",
            "https://sita.sk/feed/",
            "https://www1.pluska.sk/rss.xml",
            "https://www.sme.sk/rss-title",
            "https://spravy.pravda.sk/rss/xml/",
            "https://hnonline.sk/feed",
            "https://www1.pluska.sk/rss.xml",  # Duplicitn√©, ale nech√°me

            # üîΩ PRIDAJ TIE≈Ω TYTO FUNGUJ√öCE (testovan√©):
            "https://kosice.dnes24.sk/feed/",
            "https://bratislava.dnes24.sk/feed/",
            "https://www.korzar.sme.sk/rss/",
            "https://tech.sme.sk/rss-title",
            "https://ekonomika.sme.sk/rss-title",
            "https://sport.sme.sk/rss-title",
            "https://www.dennikn.sk/feed/",

            # üîΩ NOV√â FUNGUJ√öCE FEEDY (2024):
            "https://www.startitup.sk/feed/",
            "https://www.trend.sk/feed",
            "https://www.zive.sk/rss/",

            # Limit na 15 feedov pre r√Ωchlos≈•
        ]

        # Webov√© str√°nky pre scraping
        self.news_websites = [
            "https://www.sme.sk",
            "https://spravy.pravda.sk",
            "https://www.aktuality.sk",
            "https://www.pluska.sk"
        ]

        self.collected_file = "data/collected_news/collected_titles.csv"
        os.makedirs("data/collected_news", exist_ok=True)

        self.logger.info("‚úÖ News collector inicializovan√Ω")

    def fetch_from_rss(self, limit_per_feed: int = 25) -> List[Dict[str, str]]:
        """Z√≠skanie titulkov z RSS feedov S ODSTR√ÅNEN√çM DUPLIK√ÅTOV"""
        all_titles = []
        seen_titles = set()  # üîΩ Mno≈æina u≈æ viden√Ωch titulkov

        for feed_url in self.rss_feeds:
            try:
                self.logger.info(f"üì° Naƒç√≠tavam RSS: {feed_url}")

                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'application/rss+xml, application/xml, text/xml'
                }

                feed = feedparser.parse(feed_url, request_headers=headers)
                entries_to_process = feed.entries[:limit_per_feed] if hasattr(feed, 'entries') else []

                titles_from_feed = 0
                for entry in entries_to_process:
                    if hasattr(entry, 'title'):
                        title = entry.title.strip()

                        # üîΩ NORMALIZ√ÅCIA TITULKU
                        normalized_title = self._normalize_title(title)

                        # Preskoƒç pr√°zdne alebo pr√≠li≈° kr√°tke
                        if not normalized_title or len(normalized_title) < 15:
                            continue

                        # üîΩ KONTROLA DUPLIK√ÅTU
                        if normalized_title in seen_titles:
                            self.logger.debug(f"‚è≠Ô∏è Duplik√°t preskoƒçen√Ω: '{normalized_title}'")
                            continue

                        # Kontrola ƒçi je slovensk√Ω
                        if self._is_slovak_title(normalized_title):
                            news_item = {
                                'title': title,  # P√¥vodn√Ω titulok
                                'normalized_title': normalized_title,  # Normalizovan√Ω
                                'source': feed_url,
                                'published': entry.get('published', ''),
                                'link': entry.get('link', ''),
                                'collected_at': datetime.now().isoformat()
                            }
                            all_titles.append(news_item)
                            seen_titles.add(normalized_title)  # üîΩ Pridaj do mno≈æiny
                            titles_from_feed += 1

                self.logger.info(f"‚úÖ Z√≠skan√Ωch {titles_from_feed} titulkov z {feed_url}")

                time.sleep(0.5)

            except Exception as e:
                self.logger.error(f"‚ùå Chyba pri {feed_url}: {e}")
                continue

        self.logger.info(f"üéØ Celkovo z√≠skan√Ωch {len(all_titles)} UNIK√ÅTNYCH titulkov")
        return all_titles

    def _normalize_title(self, title: str) -> str:
        """Normaliz√°cia titulku na porovnanie duplik√°tov"""
        if not title:
            return ""

        # 1. Mal√© p√≠smen√°
        normalized = title.lower()

        # 2. Odstr√°ni≈• interpunkciu a ≈°peci√°lne znaky
        import re
        normalized = re.sub(r'[^\w\s√°√§ƒçƒè√©√≠ƒæƒ∫≈à√≥√¥≈ô≈ï≈°≈•√∫√Ω≈æ]', '', normalized)

        # 3. Odstr√°ni≈• prebytoƒçn√© medzery
        normalized = re.sub(r'\s+', ' ', normalized).strip()

        # 4. Odstr√°ni≈• ƒçast√© prefixy/suffixy
        prefixes = ['video:', 'foto:', 'video |', 'foto |', 'exkluz√≠vne:', 'breaking:']
        for prefix in prefixes:
            if normalized.startswith(prefix):
                normalized = normalized[len(prefix):].strip()

        return normalized

    def _is_slovak_title(self, title: str) -> bool:
        """Vylep≈°en√° kontrola slovensk√©ho titulku"""
        if not title:
            return False

        # Kƒæ√∫ƒçov√© slovensk√© znaky
        slovak_chars = ['√°', '√§', 'ƒç', 'ƒè', '√©', '√≠', 'ƒæ', 'ƒ∫', '≈à', '√≥', '√¥', '≈ô', '≈ï', '≈°', '≈•', '√∫', '√Ω', '≈æ']

        # Kƒæ√∫ƒçov√© slovensk√© slov√°
        slovak_words = [
            'a', 'o', 'v', 's', 'z', 'ƒço', 'ako', 'kde', 'preƒço', 'ktor√Ω', 'ktor√°', 'ktor√©',
            'pri', 'po', 'na', 'do', 'za', 'so', 'sa', 'si', 'je', 'bol', 'bola', 'bolo'
        ]

        title_lower = title.lower()

        # Kontrola pr√≠tomnosti aspo≈à 2 slovensk√Ωch znakov
        slovak_char_count = sum(1 for char in title_lower if char in slovak_chars)

        # Kontrola pr√≠tomnosti slovensk√Ωch slov
        slovak_word_count = sum(1 for word in slovak_words if word in title_lower.split())

        return slovak_char_count >= 2 or slovak_word_count >= 2

    def auto_classify_and_learn(self, self_learning_system=None, min_confidence: float = 0.0) -> List[Dict]:
        """Automatick√° klasifik√°cia s KONZISTENTNOU KLASIFIK√ÅCIOU DUPLIK√ÅTOV"""
        try:
            self.logger.info("üéØ Zaƒç√≠nam automatick√∫ klasifik√°ciu a uƒçenie...")

            news_items = self.fetch_from_rss(limit_per_feed=25)

            if not news_items:
                self.logger.info("‚ÑπÔ∏è Neboli n√°jden√© ≈æiadne nov√© titulky")
                return []

            classified_items = []
            classified_cache = {}  # üîΩ CACHE pre konzistentn√∫ klasifik√°ciu

            for item in news_items:
                title = item['title']
                normalized_title = item.get('normalized_title', self._normalize_title(title))

                # üîΩ POU≈ΩI CACHE AK U≈Ω BOL TITULOK KLASIFIKOVAN√ù
                if normalized_title in classified_cache:
                    self.logger.debug(f"üîÑ Pou≈æ√≠vam cache pre: '{normalized_title}'")
                    cached_result = classified_cache[normalized_title]

                    classified_item = {
                        **item,
                        'predicted_category': cached_result['category'],
                        'confidence': cached_result['confidence'],
                        'added_to_learning': False,  # Neprid√°va≈• do uƒçenia znovu
                        'probabilities': cached_result['probabilities']
                    }
                    classified_items.append(classified_item)
                    continue

                # Norm√°lna klasifik√°cia
                if len(title) < 15:
                    continue

                try:
                    if self_learning_system and self.classifier:
                        category, probabilities, added_to_learning = self_learning_system.predict_with_learning(title)
                    elif self.classifier:
                        category, probabilities = self.classifier.predict(title)
                        added_to_learning = False
                    else:
                        continue

                    confidence = max(probabilities.values())

                    if confidence < min_confidence:
                        continue

                    # üîΩ ULO≈Ω DO CACHE
                    classified_cache[normalized_title] = {
                        'category': category,
                        'confidence': confidence,
                        'probabilities': probabilities
                    }

                    classified_item = {
                        **item,
                        'predicted_category': category,
                        'confidence': confidence,
                        'added_to_learning': added_to_learning,
                        'probabilities': probabilities
                    }
                    classified_items.append(classified_item)

                    if confidence > 0.8:
                        self.logger.info(f"üéØ {category}: '{title[:50]}...' ({confidence:.3f})")

                except Exception as e:
                    self.logger.error(f"Chyba pri klasifik√°cii: {e}")
                    continue

            # Ulo≈æenie v√Ωsledkov
            self._save_collected_news(classified_items)

            # üîΩ LOGOVANIE ≈†TATIST√çK
            unique_titles = len(set(item.get('normalized_title', self._normalize_title(item['title']))
                                    for item in classified_items))
            self.logger.info(f"‚úÖ Spracovan√Ωch {len(classified_items)} titulkov ({unique_titles} unik√°tnych)")

            return classified_items

        except Exception as e:
            self.logger.error(f"‚ùå Chyba v auto_classify_and_learn: {e}")
            return []
    def _save_collected_news(self, news_items: List[Dict]):
        """Ulo≈æenie nazbieran√Ωch titulkov"""
        try:
            if not news_items:
                return

            # Naƒç√≠tanie existuj√∫cich d√°t
            try:
                existing_df = pd.read_csv(self.collected_file)
            except FileNotFoundError:
                existing_df = pd.DataFrame()

            # Pridanie nov√Ωch d√°t
            new_df = pd.DataFrame(news_items)
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)

            # Odstr√°nenie duplik√°tov
            combined_df = combined_df.drop_duplicates(subset=['title'])

            # Ulo≈æenie
            combined_df.to_csv(self.collected_file, index=False)

            self.logger.info(f"üíæ Ulo≈æen√Ωch {len(new_df)} nov√Ωch titulkov")

        except Exception as e:
            self.logger.error(f"Chyba pri ukladan√≠ titulkov: {e}")

    def get_recent_news(self, hours: int = 24) -> pd.DataFrame:
        """
        Z√≠skanie ned√°vno nazbieran√Ωch titulkov

        Args:
            hours: Poƒçet hodien dozadu

        Returns:
            DataFrame s ned√°vnymi titulkami
        """
        try:
            df = pd.read_csv(self.collected_file)

            # Filtr podƒæa ƒçasu
            if 'collected_at' in df.columns:
                df['collected_at'] = pd.to_datetime(df['collected_at'])
                cutoff_time = datetime.now() - pd.Timedelta(hours=hours)
                recent_df = df[df['collected_at'] > cutoff_time]
            else:
                recent_df = df.tail(50)  # Posledn√Ωch 50 ak nie je ƒçasov√° znaƒçka

            return recent_df

        except FileNotFoundError:
            self.logger.info("S√∫bor s nazbieran√Ωmi titulkmi neexistuje")
            return pd.DataFrame()
        except Exception as e:
            self.logger.error(f"Chyba pri naƒç√≠tavan√≠ recent news: {e}")
            return pd.DataFrame()

    def get_news_stats(self) -> Dict[str, any]:
        """≈†tatistiky nazbieran√Ωch spr√°v"""
        try:
            df = self.get_recent_news(hours=168)  # Posledn√Ω t√Ω≈æde≈à

            if df.empty:
                return {'total_news': 0}

            stats = {
                'total_news': len(df),
                'sources': df['source'].value_counts().to_dict(),
                'categories': df[
                    'predicted_category'].value_counts().to_dict() if 'predicted_category' in df.columns else {},
                'high_confidence_news': len(df[df['confidence'] > 0.8]) if 'confidence' in df.columns else 0
            }

            return stats

        except Exception as e:
            self.logger.error(f"Chyba pri z√≠skavan√≠ ≈°tatist√≠k: {e}")
            return {}