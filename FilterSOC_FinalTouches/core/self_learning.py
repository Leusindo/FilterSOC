# core/self_learning.py
import pandas as pd
import numpy as np
import logging
import joblib
import os
from datetime import datetime
from typing import List, Dict, Tuple
from .config import Config


# core/self_learning.py - PRIDAJ T√öTO MET√ìDU:

class SelfLearningSystem:
    def __init__(self, classifier, aggressive_learning=True):
        self.classifier = classifier
        self.config = Config()
        self.logger = logging.getLogger(__name__)

        # üöÄ EXTREME AGGRESSIVE LEARNING
        self.confidence_threshold = 0.0  # Uƒç√≠ sa zo v≈°etk√©ho
        self.buffer_size = 10  # Veƒæmi r√Ωchle pretr√©novanie
        self.aggressive_learning = True  # V≈ædy zapnut√©

        self.learning_buffer = []
        self.learning_file = "data/self_learning/learning_data.csv"
        self.backup_file = "data/self_learning/learning_data_backup.csv"

        os.makedirs("data/self_learning", exist_ok=True)
        self._initialize_learning_data()

        self.logger.info("üöÄ EXTREME AGGRESSIVE LEARNING - Uƒç√≠ sa zo v≈°etk√Ωch predikci√≠!")

    def _initialize_learning_data(self):
        """Inicializ√°cia learning d√°t s potrebn√Ωmi stƒ∫pcami"""
        try:
            # Sk√∫s naƒç√≠ta≈• existuj√∫ce d√°ta
            learning_data = self.load_learning_data()

            # Ak s√∫bor existuje ale ch√Ωbaj√∫ stƒ∫pce, pridaj ich
            if not learning_data.empty:
                required_columns = ['text', 'category', 'confidence', 'timestamp', 'verified', 'processed']
                missing_columns = [col for col in required_columns if col not in learning_data.columns]

                if missing_columns:
                    self.logger.info(f"üîß Prid√°vam ch√Ωbaj√∫ce stƒ∫pce: {missing_columns}")
                    for col in missing_columns:
                        if col == 'verified':
                            learning_data[col] = False
                        elif col == 'processed':
                            learning_data[col] = False
                        elif col == 'timestamp':
                            learning_data[col] = datetime.now().isoformat()
                        else:
                            learning_data[col] = ''

                    learning_data.to_csv(self.learning_file, index=False)
                    self.logger.info("‚úÖ Learning data inicializovan√© s potrebn√Ωmi stƒ∫pcami")

        except Exception as e:
            self.logger.info("üìù Vytv√°ram nov√Ω learning data s√∫bor")
            # Vytvor pr√°zdny DataFrame s potrebn√Ωmi stƒ∫pcami
            empty_df = pd.DataFrame(columns=['text', 'category', 'confidence', 'timestamp', 'verified', 'processed'])
            empty_df.to_csv(self.learning_file, index=False)

    def predict_with_learning(self, text: str) -> Tuple[str, Dict[str, float], bool]:
        """
        Predikcia s mo≈ænos≈•ou uƒçenia z vysokospoƒæahliv√Ωch predikci√≠

        Returns:
            Tuple: (kateg√≥ria, pravdepodobnosti, pridan√©_do_√∫ƒçenia)
        """
        try:
            # ≈†tandardn√° predikcia
            category, probabilities = self.classifier.predict(text)
            confidence = max(probabilities.values())

            # Kontrola ƒçi prid√°me do uƒçenia
            added_to_learning = False
            if confidence > self.confidence_threshold:
                self._add_to_learning_buffer(text, category, confidence)
                added_to_learning = True
                self.logger.info(f"üß† Pridan√© do uƒçenia: '{text}' -> {category} ({confidence:.3f})")

            return category, probabilities, added_to_learning

        except Exception as e:
            self.logger.error(f"Chyba v predict_with_learning: {e}")
            return "unknown", {}, False

    def _add_to_learning_buffer(self, text: str, category: str, confidence: float):
        """Pridanie pr√≠kladu do uƒçiaceho bufferu"""
        learning_example = {
            'text': text,
            'category': category,
            'confidence': confidence,
            'timestamp': datetime.now().isoformat(),
            'verified': False,  # M√¥≈æe by≈• nesk√¥r overen√© pou≈æ√≠vateƒæom
            'processed': False  # Oznaƒçenie ƒçi bol pou≈æit√Ω pri pretr√©novan√≠
        }

        self.learning_buffer.append(learning_example)

        # Auto-ukladanie ka≈æd√Ωch 10 pr√≠kladov
        if len(self.learning_buffer) >= 10:
            self._save_learning_data()

        # Kontrola ƒçi netreba pretr√©nova≈•
        if len(self.learning_buffer) >= self.buffer_size:
            self.logger.info(f"üîÑ Buffer pln√Ω ({len(self.learning_buffer)} pr√≠kladov), navrhujem pretr√©novanie")

    def _save_learning_data(self):
        """Ulo≈æenie uƒçiacich d√°t do CSV"""
        try:
            if not self.learning_buffer:
                return

            # Naƒç√≠tanie existuj√∫cich d√°t
            try:
                existing_df = pd.read_csv(self.learning_file)
            except FileNotFoundError:
                # Vytvorenie nov√©ho DataFrame s potrebn√Ωmi stƒ∫pcami
                existing_df = pd.DataFrame(
                    columns=['text', 'category', 'confidence', 'timestamp', 'verified', 'processed'])

            # Pridanie nov√Ωch d√°t
            new_df = pd.DataFrame(self.learning_buffer)
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)

            # Odstr√°nenie duplik√°tov
            combined_df = combined_df.drop_duplicates(subset=['text'])

            # Ulo≈æenie
            combined_df.to_csv(self.learning_file, index=False)
            combined_df.to_csv(self.backup_file, index=False)  # Z√°loha

            self.logger.info(f"üíæ Ulo≈æen√Ωch {len(new_df)} self-learning pr√≠kladov")
            self.learning_buffer.clear()

        except Exception as e:
            self.logger.error(f"Chyba pri ukladan√≠ learning d√°t: {e}")

    def load_learning_data(self) -> pd.DataFrame:
        """Naƒç√≠tanie existuj√∫cich uƒçiacich d√°t"""
        try:
            df = pd.read_csv(self.learning_file)

            # Kontrola a doplnenie ch√Ωbaj√∫cich stƒ∫pcov
            required_columns = ['text', 'category', 'confidence', 'timestamp', 'verified', 'processed']
            for col in required_columns:
                if col not in df.columns:
                    if col == 'verified':
                        df[col] = False
                    elif col == 'processed':
                        df[col] = False
                    elif col == 'timestamp':
                        df[col] = datetime.now().isoformat()
                    else:
                        df[col] = ''

            self.logger.info(f"üìñ Naƒç√≠tan√Ωch {len(df)} self-learning pr√≠kladov")
            return df

        except FileNotFoundError:
            self.logger.info("Self-learning s√∫bor neexistuje, vr√°ten√Ω pr√°zdny DataFrame")
            return pd.DataFrame()
        except Exception as e:
            self.logger.error(f"Chyba pri naƒç√≠tavan√≠ learning d√°t: {e}")
            return pd.DataFrame()

    # core/self_learning.py - OPRAV met√≥du retrain_with_learning_data():

    def retrain_with_learning_data(self) -> bool:
        """
        Pretr√©novanie modelu s nov√Ωmi uƒçiacimi d√°tami
        """
        try:
            self.logger.info("üîÑ Zaƒç√≠nam pretr√©novanie s self-learning d√°tami...")

            # Naƒç√≠tanie p√¥vodn√Ωch a nov√Ωch d√°t
            original_data = pd.read_csv(self.config.DATA_PATH)
            learning_data = self.load_learning_data()

            if learning_data.empty:
                self.logger.info("‚ÑπÔ∏è ≈Ωiadne learning d√°ta pre pretr√©novanie")
                return False

            # üîΩ D√îLE≈ΩIT√Å OPRAVA: Zme≈à filtrovanie!
            # P√îVODN√â (zl√©):
            # verified_mask = (
            #     (learning_data.get('verified', pd.Series([False] * len(learning_data))) == True) |
            #     (learning_data.get('confidence', pd.Series([0] * len(learning_data))) > 0.9)
            # )

            # OPRAVEN√â (jednoduch≈°ie):
            # 1. Zober v≈°etky pr√≠klady ktor√© s√∫ overen√© ALEBO maj√∫ vysok√∫ istotu
            verified_mask = pd.Series([True] * len(learning_data))  # V≈°etky pr√≠klady!

            # Alebo e≈°te lep≈°ie:
            # verified_mask = (
            #     learning_data.get('verified', pd.Series([False] * len(learning_data)).fillna(False)) |
            #     (learning_data.get('confidence', pd.Series([0.0] * len(learning_data)).fillna(0.0)) > 0.25)
            # )

            verified_data = learning_data[verified_mask]

            if len(verified_data) == 0:
                self.logger.info("‚ÑπÔ∏è ≈Ωiadne overen√© d√°ta pre pretr√©novanie")
                return False

            self.logger.info(f"üìä Pretr√©nujem s {len(verified_data)} overen√Ωmi pr√≠kladmi")

            # Vytvorenie zl√∫ƒçen√©ho datasetu
            new_data = pd.DataFrame({
                'title': verified_data['text'],
                'category': verified_data['category']
            })

            combined_data = pd.concat([original_data, new_data], ignore_index=True)

            # Ulo≈æenie z√°lohy p√¥vodn√©ho modelu
            self._backup_current_models()

            # üîΩ OPRAVA: Resetuj feature extractor pred pretr√©novan√≠m
            self.classifier.feature_extractor.is_fitted = False

            # Pretr√©novanie klasifik√°tora
            results = self.classifier.train(enable_augmentation=False)

            self.logger.info(f"‚úÖ Pretr√©novanie √∫spe≈°n√©! Nov√° presnos≈•: {results['accuracy']:.3f}")

            # Oznaƒçenie pou≈æit√Ωch pr√≠kladov ako spracovan√Ωch
            self._mark_processed_examples(verified_data)

            return True

        except Exception as e:
            self.logger.error(f"‚ùå Chyba pri pretr√©novan√≠: {e}")
            self._restore_backup_models()  # Obnova z√°lohy
            return False

    def _backup_current_models(self):
        """Z√°lohovanie aktu√°lnych modelov"""
        import shutil
        import glob

        try:
            model_files = glob.glob(os.path.join(self.config.MODELS_DIR, "*"))
            for file_path in model_files:
                if os.path.isfile(file_path):
                    filename = os.path.basename(file_path)
                    shutil.copy2(file_path, f"data/backup_models/{filename}")

            self.logger.info("üíæ Aktu√°lne modely zaz√°lohovan√©")
        except Exception as e:
            self.logger.error(f"Chyba pri z√°lohovan√≠ modelov: {e}")

    def _restore_backup_models(self):
        """Obnova modelov zo z√°lohy"""
        import shutil
        import glob

        try:
            backup_files = glob.glob("data/backup_models/*")
            for file_path in backup_files:
                if os.path.isfile(file_path):
                    filename = os.path.basename(file_path)
                    shutil.copy2(file_path, os.path.join(self.config.MODELS_DIR, filename))

            self.logger.info("üîÑ Modely obnoven√© zo z√°lohy")
            self.classifier.load_models()  # Re-naƒç√≠tanie modelov
        except Exception as e:
            self.logger.error(f"Chyba pri obnove modelov: {e}")

    def _mark_processed_examples(self, processed_data: pd.DataFrame):
        """Oznaƒçenie spracovan√Ωch pr√≠kladov"""
        try:
            learning_data = self.load_learning_data()

            if learning_data.empty:
                return

            # BEZPEƒåN√Å KONTROLA - vytvorenie stƒ∫pca ak neexistuje
            if 'processed' not in learning_data.columns:
                learning_data['processed'] = False

            # Oznaƒçenie pou≈æit√Ωch pr√≠kladov
            processed_texts = set(processed_data['text'])
            learning_data['processed'] = learning_data['text'].isin(processed_texts)

            learning_data.to_csv(self.learning_file, index=False)
            self.logger.info(f"üè∑Ô∏è Oznaƒçen√Ωch {len(processed_texts)} pr√≠kladov ako spracovan√Ωch")

        except Exception as e:
            self.logger.error(f"Chyba pri oznaƒçovan√≠ pr√≠kladov: {e}")

    def get_learning_stats(self) -> Dict[str, any]:
        """≈†tatistiky self-learning syst√©mu"""
        try:
            learning_data = self.load_learning_data()
            buffer_size = len(self.learning_buffer)

            stats = {
                'buffer_size': buffer_size,
                'saved_examples': len(learning_data),
                'ready_for_retrain': buffer_size >= self.buffer_size,
                'confidence_threshold': self.confidence_threshold
            }

            # BEZPEƒåN√â POƒå√çTANIE - kontrola existencie stƒ∫pcov
            if not learning_data.empty:
                # Overen√© pr√≠klady
                if 'verified' in learning_data.columns:
                    stats['verified_examples'] = len(learning_data[learning_data['verified'] == True])
                else:
                    stats['verified_examples'] = 0

                # Vysoko istotn√© pr√≠klady
                if 'confidence' in learning_data.columns:
                    stats['high_confidence_examples'] = len(learning_data[learning_data['confidence'] > 0.9])
                else:
                    stats['high_confidence_examples'] = 0

            # Rozdelenie podƒæa kateg√≥ri√≠
            if not learning_data.empty and 'category' in learning_data.columns:
                category_counts = learning_data['category'].value_counts().to_dict()
                stats['category_distribution'] = category_counts

            return stats

        except Exception as e:
            self.logger.error(f"Chyba pri z√≠skavan√≠ ≈°tatist√≠k: {e}")
            return {
                'buffer_size': len(self.learning_buffer),
                'saved_examples': 0,
                'verified_examples': 0,
                'high_confidence_examples': 0,
                'ready_for_retrain': False,
                'confidence_threshold': self.confidence_threshold
            }

    def manual_verification(self, text: str, correct_category: str):
        """
        Manu√°lne overenie a pridanie pr√≠kladu do uƒçenia
        """
        try:
            learning_example = {
                'text': text,
                'category': correct_category,
                'confidence': 1.0,  # Maxim√°lna istota pre manu√°lne overen√©
                'timestamp': datetime.now().isoformat(),
                'verified': True,
                'processed': False
            }

            self.learning_buffer.append(learning_example)
            self._save_learning_data()

            self.logger.info(f"‚úÖ Manu√°lne overen√©: '{text}' -> {correct_category}")

        except Exception as e:
            self.logger.error(f"Chyba pri manu√°lnom overen√≠: {e}")